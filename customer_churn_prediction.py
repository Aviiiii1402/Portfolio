# -*- coding: utf-8 -*-
"""Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7RnWuyxqRoDrVjVRRyBoIeqCNlWS2ZG
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(list(uploaded.keys())[0])

# Display the first few rows of the DataFrame
df.head()

# Display summary information about the dataset
print(df.info())

# Check for missing values
print(df.isnull().sum())

# check for dat types
df.info()

# check classes ratio
df.groupby(['churn'])['churn'].count()

import matplotlib.pyplot as plt

# Histogram
df.hist(figsize=(12, 8))
plt.show()

# boxplots to check for outliers
df.select_dtypes(include=['number']).plot(kind='box', subplots=True, layout=(2, -1), figsize=(12, 8), sharex=False, sharey=False)
plt.show()

import seaborn as sns

# Identify categorical columns
categorical_columns = df.select_dtypes(include=['object']).columns

# Create bar plots for categorical features
for col in categorical_columns:
    sns.countplot(data=df, x=col)
    plt.show()

#Correlation matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df['churn'] = df['churn'].astype(int)
df

# Separate numerical features
numerical_features = df.select_dtypes(include=['float64', 'int64'])

# Calculate the correlation matrix
correlation_matrix = numerical_features.corr()

# Plot the correlation matrix with a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# Calculate correlation with the target variable
correlation_with_target = numerical_features.corrwith(df['churn'])

# Plot the correlation of each feature with the target variable
plt.figure(figsize=(10, 6))
correlation_with_target.sort_values(ascending=False).plot(kind='bar', color='skyblue')
plt.title('Correlation of Numerical Features with Target Variable')
plt.show()

df.info()

## Columns to Remove - total day minutes, total eve minutes, total night minutes, total international minutes

# List of columns to remove
columns_to_remove = ['total day minutes', 'total eve minutes', 'total night minutes', 'total intl minutes', 'phone number']

# Remove the specified columns
dataframe_cleaned = df.drop(columns=columns_to_remove)

# Display the first few rows of the cleaned dataset to verify
dataframe_cleaned.head()

# Separate numerical features
numerical_features = dataframe_cleaned.select_dtypes(include=['float64', 'int64'])

# Calculate the correlation matrix
correlation_matrix = numerical_features.corr()

# Plot the correlation matrix with a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# Calculate correlation with the target variable
correlation_with_target = numerical_features.corrwith(dataframe_cleaned['churn'])

# Plot the correlation of each feature with the target variable
plt.figure(figsize=(10, 6))
correlation_with_target.sort_values(ascending=False).plot(kind='bar', color='skyblue')
plt.title('Correlation of Numerical Features with Target Variable')
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler

# Get dummies for categorical columns
dataframe_cleaned = pd.get_dummies(dataframe_cleaned, drop_first=True)

# Convert any boolean columns to integers
boolean_columns = dataframe_cleaned.select_dtypes(include=['bool']).columns
dataframe_cleaned[boolean_columns] = dataframe_cleaned[boolean_columns].astype(int)

dataframe_cleaned.info()

# Separate features and target
X = dataframe_cleaned.drop(columns=['churn'])  # Replace 'churn' with your actual target column name
y = dataframe_cleaned['churn']

# Standardize the numerical features
scaler = StandardScaler()

# Identify numerical columns
numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns

# Apply standardization
X[numerical_columns] = scaler.fit_transform(X[numerical_columns])

X.head()

y.head()

from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Initialize and train the XGBoost classifier
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)

# Make predictions
y_pred = xgb_model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Plot feature importance
importance = xgb_model.feature_importances_
feature_names = X.columns

